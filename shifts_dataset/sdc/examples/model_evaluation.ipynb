{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c973b3ac",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Mapping\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from sdc.config import build_parser\n",
    "from sdc.oatomobile.torch.baselines import init_rip\n",
    "from sdc.oatomobile.torch.baselines.robust_imitative_planning import \\\n",
    "    load_rip_checkpoints\n",
    "from ysdc_dataset_api.dataset import MotionPredictionDataset\n",
    "from ysdc_dataset_api.evaluation.utils import load_submission_proto, save_submission_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset_path = '/path/to/datasets/evaluation_pb/'\n",
    "prerendered_dataset_path = '/path/to/dataset/evaluation_rendered/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95dbd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset = MotionPredictionDataset(\n",
    "    dataset_path=evaluation_dataset_path,\n",
    "    prerendered_dataset_path=prerendered_dataset_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a6bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset.num_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2208bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = build_parser()\n",
    "args = parser.parse_args('')\n",
    "\n",
    "\n",
    "def ipynb_patch_args(args):\n",
    "    args.dir_checkpoint = '/path/to/model_checkpoints'\n",
    "\n",
    "    # The below configuration was our best performing in baseline experiments.\n",
    "    # See paper for more details and the configurations considered.\n",
    "    \n",
    "    # Backbone model details\n",
    "    # Behavioral Cloning: \n",
    "    # MobileNetv2 feature encoder, GRU decoder\n",
    "    args.model_name = 'bc'\n",
    "    args.model_dim_hidden = 512\n",
    "    args.exp_device = 'cuda:0'\n",
    "    \n",
    "    # Used in scoring generated trajectories and obtaining \n",
    "    # per-plan/per-scene confidence scores.\n",
    "    # See \n",
    "    #   `sdc.oatomobile.torch.baselines.robust_imitative_planning.py` \n",
    "    # for details.\n",
    "    args.rip_per_plan_algorithm = 'MA'\n",
    "    args.rip_per_scene_algorithm = 'MA'\n",
    "    \n",
    "    # Number of ensemble members\n",
    "    args.rip_k = 5\n",
    "    \n",
    "    # Data loading\n",
    "    # https://pytorch.org/docs/stable/data.html\n",
    "    args.exp_batch_size = 512\n",
    "    args.data_num_workers = 10\n",
    "    args.data_prefetch_factor = 2\n",
    "    \n",
    "    # Cache loss metrics here\n",
    "    args.dir_metrics = '/path/to/metrics'\n",
    "\n",
    "    return args\n",
    "\n",
    "c = ipynb_patch_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82d0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, c):\n",
    "        self.c = c\n",
    "    \n",
    "        # Initialize torch hub dir to cache MobileNetV2\n",
    "        torch.hub.set_dir(f'{c.dir_checkpoint}/torch_hub')\n",
    "        \n",
    "    def load(self):\n",
    "        model, self.full_model_name, _, _ = init_rip(c=self.c)\n",
    "        checkpoint_dir = f'{c.dir_checkpoint}/{self.full_model_name}'\n",
    "        self.model = load_rip_checkpoints(\n",
    "            model=model, device=c.exp_device, k=c.rip_k,\n",
    "            checkpoint_dir=checkpoint_dir)\n",
    "        \n",
    "    \n",
    "    def predict(self, batch: Mapping[str, torch.Tensor], sdc_loss: Optional[SDCLoss]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch: Mapping[str, torch.Tensor], with 'feature_maps' key/value\n",
    "\n",
    "        Returns:\n",
    "            Sequence of dicts. Each has the following structure:\n",
    "                {\n",
    "                    predictions_list: Sequence[np.ndarray],\n",
    "                    plan_confidence_scores_list: Sequence[np.ndarray],\n",
    "                    pred_request_uncertainty_measure: float,\n",
    "                }\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions, plan_confidence_scores, pred_request_confidence_scores = (\n",
    "                self.model(**batch))\n",
    "            \n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "        plan_confidence_scores = plan_confidence_scores.detach().cpu().numpy()\n",
    "        pred_request_confidence_scores = pred_request_confidence_scores.detach().cpu().numpy()\n",
    "        \n",
    "        if sdc_loss is not None:\n",
    "            ground_truth = batch['ground_truth_trajectory'].detach().cpu().numpy()\n",
    "            sdc_loss.cache_batch_losses(\n",
    "                predictions_list=predictions,\n",
    "                ground_truth_batch=ground_truth,\n",
    "                plan_confidence_scores_list=plan_confidence_scores,\n",
    "                pred_request_confidence_scores=pred_request_confidence_scores)\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                'predictions_list': predictions[i],\n",
    "                'plan_confidence_scores_list': plan_confidence_scores[i],\n",
    "                # Negate, as we need to provide an uncertainty measure\n",
    "                # for the submission pb, not a confidence score.\n",
    "                'pred_request_uncertainty_measure':\n",
    "                    -(pred_request_confidence_scores[i])\n",
    "            } for i in range(predictions.shape[0])]\n",
    "\n",
    "# Initialize and load ensemble of k models from checkpoints\n",
    "# On first run, will fail and create a directory where checkpoints\n",
    "# should be placed.\n",
    "model = Model(c=c)\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init dataloader\n",
    "dataloader_kwargs = {\n",
    "    'batch_size': c.exp_batch_size,\n",
    "    'num_workers': c.data_num_workers,\n",
    "    'prefetch_factor': c.data_prefetch_factor,\n",
    "    'pin_memory': True\n",
    "}\n",
    "\n",
    "print(f'Building dataloaders with kwargs {dataloader_kwargs}.')\n",
    "evaluation_dataloader = torch.utils.data.DataLoader(evaluation_dataset, **dataloader_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54a748",
   "metadata": {},
   "source": [
    "### Produce a Submission Protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e1943",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = Submission()\n",
    "\n",
    "batch_cast = partial(\n",
    "    batch_transform, device=c.exp_device, downsample_hw=None,\n",
    "    data_use_prerendered=True)\n",
    "\n",
    "for batch_id, batch in enumerate(tqdm.tqdm(evaluation_dataloader)):\n",
    "    batch = batch_cast(batch)\n",
    "    batch_output = model.predict(batch, None)\n",
    "\n",
    "    for i, data_item_output in enumerate(batch_output):\n",
    "        proto = object_prediction_from_model_output(\n",
    "            track_id=batch['track_id'][i],\n",
    "            scene_id=batch['scene_id'][i],\n",
    "            model_output=data_item_output,\n",
    "            is_ood=False)  # Set fake value as we do not know is_ood for evaluation data.\n",
    "\n",
    "        submission.predictions.append(proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aee30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's write out a submission protobuf (as one should submit for the competition).\n",
    "save_submission_proto('eval_moscow_and_ood_submission.pb', submission=submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can check that things were written correctly as follows:\n",
    "new_sub = load_submission_proto('eval_moscow_and_ood_submission.pb')\n",
    "len(new_sub.predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
