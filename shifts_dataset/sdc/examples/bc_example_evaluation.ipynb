{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c973b3ac",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a5d08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/master/10/cytseng/miniconda3/envs/sdc/lib/python3.8/site-packages/ysdc_dataset_api/utils/transform.py:90: NumbaPerformanceWarning: '@' is faster on contiguous arrays, called on (array(float32, 2d, A), array(float32, 2d, C))\n",
      "  res = transform @ ph\n",
      "/home/master/10/cytseng/miniconda3/envs/sdc/lib/python3.8/site-packages/numba/core/typing/npydecl.py:965: NumbaPerformanceWarning: '@' is faster on contiguous arrays, called on (array(float32, 2d, A), array(float32, 2d, C))\n",
      "  warnings.warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "from typing import Mapping\n",
    "from typing import Optional\n",
    "from functools import partial\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm.notebook as tqdm\n",
    "from sdc.metrics import SDCLoss\n",
    "from sdc.config import build_parser\n",
    "from sdc.oatomobile.torch.baselines import init_rip\n",
    "from sdc.oatomobile.torch.baselines.robust_imitative_planning import load_rip_checkpoints\n",
    "from ysdc_dataset_api.dataset import MotionPredictionDataset\n",
    "from ysdc_dataset_api.evaluation.utils import load_submission_proto, save_submission_proto\n",
    "from ysdc_dataset_api.evaluation import Submission, object_prediction_from_model_output, save_submission_proto\n",
    "from sdc.oatomobile.torch.baselines import batch_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7925c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f8f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset_path = \\\n",
    "'/home/master/10/cytseng/shifts_sdc_dataset/canonical-eval-data/evaluation'\n",
    "prerendered_dataset_path = \\\n",
    "'/home/master/10/cytseng/shifts_sdc_dataset/canonical-eval-data/evaluation_renders'\n",
    "\n",
    "# Submission_dir\n",
    "submission_dir = '/home/master/10/cytseng/shifts_eval/shifts/sdc/submissions_eval/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95dbd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset = MotionPredictionDataset(\n",
    "    dataset_path=evaluation_dataset_path,\n",
    "    prerendered_dataset_path=prerendered_dataset_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e4a6bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36804"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataset.num_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2208bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = build_parser()\n",
    "args = parser.parse_args('')\n",
    "\n",
    "\n",
    "def ipynb_patch_args(args):\n",
    "    args.dir_checkpoint = '/home/master/10/cytseng/shifts_eval/shifts/sdc/model_checkpoints'\n",
    "\n",
    "    # The below configuration was our best performing in baseline experiments.\n",
    "    # See paper for more details and the configurations considered.\n",
    "    \n",
    "    # Backbone model details\n",
    "    # Behavioral Cloning: \n",
    "    # MobileNetv2 feature encoder, GRU decoder\n",
    "    args.model_name = 'bc'\n",
    "    args.model_dim_hidden = 512\n",
    "    args.exp_device = 'cuda:0'\n",
    "    \n",
    "    # Used in scoring generated trajectories and obtaining \n",
    "    # per-plan/per-scene confidence scores.\n",
    "    # See \n",
    "    #   `sdc.oatomobile.torch.baselines.robust_imitative_planning.py` \n",
    "    # for details.\n",
    "    args.rip_per_plan_algorithm = 'MA'\n",
    "    args.rip_per_scene_algorithm = 'MA'\n",
    "    \n",
    "    # Number of ensemble members\n",
    "    args.rip_k = 5\n",
    "    \n",
    "    # Data loading\n",
    "    # https://pytorch.org/docs/stable/data.html\n",
    "    args.exp_batch_size = 512\n",
    "    args.data_num_workers = 4\n",
    "    args.data_prefetch_factor = 2\n",
    "    \n",
    "    # Cache loss metrics here\n",
    "    args.dir_metrics = '/home/master/10/cytseng/shifts_sdc_dataset/data/metrics'\n",
    "\n",
    "    return args\n",
    "\n",
    "c = ipynb_patch_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9464b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax for normalize\n",
    "def _softmax_normalize(weights: np.ndarray) -> np.ndarray:\n",
    "    weights = np.exp(weights - np.max(weights))\n",
    "    return weights / weights.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b82d0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIP kwargs:\n",
      "{'cache_all_preds': False,\n",
      " 'device': 'cuda:0',\n",
      " 'k': 5,\n",
      " 'model_name': 'bc',\n",
      " 'num_preds': 5,\n",
      " 'per_plan_algorithm': 'MA',\n",
      " 'per_scene_algorithm': 'MA',\n",
      " 'samples_per_model': 10}\n",
      "Building RIP agent with backbone model bc, per-plan algorithm MA, per-scene algorithm MA, 5 ensemble members.\n",
      "Model kwargs:\n",
      "{'bc_deterministic': False,\n",
      " 'device': 'cuda:0',\n",
      " 'dim_hidden': 512,\n",
      " 'generation_mode': 'sampling',\n",
      " 'in_channels': 17,\n",
      " 'output_shape': (25, 2)}\n",
      "BC Model: using Gaussian likelihood.\n",
      "BC Model: using generation mode sampling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/master/10/cytseng/shifts_eval/shifts/sdc/model_checkpoints/torch_hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kwargs:\n",
      "{'bc_deterministic': False,\n",
      " 'device': 'cuda:0',\n",
      " 'dim_hidden': 512,\n",
      " 'generation_mode': 'sampling',\n",
      " 'in_channels': 17,\n",
      " 'output_shape': (25, 2)}\n",
      "BC Model: using Gaussian likelihood.\n",
      "BC Model: using generation mode sampling.\n",
      "Model kwargs:\n",
      "{'bc_deterministic': False,\n",
      " 'device': 'cuda:0',\n",
      " 'dim_hidden': 512,\n",
      " 'generation_mode': 'sampling',\n",
      " 'in_channels': 17,\n",
      " 'output_shape': (25, 2)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/master/10/cytseng/shifts_eval/shifts/sdc/model_checkpoints/torch_hub/pytorch_vision_v0.9.0\n",
      "Using cache found in /home/master/10/cytseng/shifts_eval/shifts/sdc/model_checkpoints/torch_hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC Model: using Gaussian likelihood.\n",
      "BC Model: using generation mode sampling.\n",
      "Model kwargs:\n",
      "{'bc_deterministic': False,\n",
      " 'device': 'cuda:0',\n",
      " 'dim_hidden': 512,\n",
      " 'generation_mode': 'sampling',\n",
      " 'in_channels': 17,\n",
      " 'output_shape': (25, 2)}\n",
      "BC Model: using Gaussian likelihood.\n",
      "BC Model: using generation mode sampling.\n",
      "Model kwargs:\n",
      "{'bc_deterministic': False,\n",
      " 'device': 'cuda:0',\n",
      " 'dim_hidden': 512,\n",
      " 'generation_mode': 'sampling',\n",
      " 'in_channels': 17,\n",
      " 'output_shape': (25, 2)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/master/10/cytseng/shifts_eval/shifts/sdc/model_checkpoints/torch_hub/pytorch_vision_v0.9.0\n",
      "Using cache found in /home/master/10/cytseng/shifts_eval/shifts/sdc/model_checkpoints/torch_hub/pytorch_vision_v0.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC Model: using Gaussian likelihood.\n",
      "BC Model: using generation mode sampling.\n",
      "Loaded ensemble member 1 from path /home/master/10/cytseng/shifts_eval/shifts/sdc/model_checkpoints/rip-bc-k_5-plan_ma-scene_ma/model-seed-90-epoch-83.pt\n",
      "Loaded ensemble member 2 from path /home/master/10/cytseng/shifts_eval/shifts/sdc/model_checkpoints/rip-bc-k_5-plan_ma-scene_ma/model-seed-10-epoch-57.pt\n",
      "Loaded ensemble member 3 from path /home/master/10/cytseng/shifts_eval/shifts/sdc/model_checkpoints/rip-bc-k_5-plan_ma-scene_ma/model-seed-20-epoch-90.pt\n",
      "Loaded ensemble member 4 from path /home/master/10/cytseng/shifts_eval/shifts/sdc/model_checkpoints/rip-bc-k_5-plan_ma-scene_ma/model-seed-60-epoch-64.pt\n",
      "Loaded ensemble member 5 from path /home/master/10/cytseng/shifts_eval/shifts/sdc/model_checkpoints/rip-bc-k_5-plan_ma-scene_ma/model-seed-40-epoch-78.pt\n",
      "Successfully loaded all 5 ensemble members.\n"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self, c):\n",
    "        self.c = c\n",
    "        # Initialize torch hub dir to cache MobileNetV2\n",
    "        torch.hub.set_dir(f'{c.dir_checkpoint}/torch_hub')\n",
    "        \n",
    "    def load(self):\n",
    "        model, self.full_model_name, _, _ = init_rip(c=self.c)\n",
    "        checkpoint_dir = f'{c.dir_checkpoint}/{self.full_model_name}'\n",
    "        self.model = load_rip_checkpoints(\n",
    "            model=model, device=c.exp_device, k=c.rip_k,\n",
    "            checkpoint_dir=checkpoint_dir)\n",
    "        \n",
    "    \n",
    "    def predict(self, batch: Mapping[str, torch.Tensor], sdc_loss: Optional[SDCLoss]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch: Mapping[str, torch.Tensor], with 'feature_maps' key/value\n",
    "\n",
    "        Returns:\n",
    "            Sequence of dicts. Each has the following structure:\n",
    "                {\n",
    "                    predictions_list: Sequence[np.ndarray],\n",
    "                    plan_confidence_scores_list: Sequence[np.ndarray],\n",
    "                    pred_request_uncertainty_measure: float,\n",
    "                }\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions, plan_confidence_scores, pred_request_confidence_scores = (\n",
    "                self.model(**batch))\n",
    "            \n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "#         print(\"predictions: \", predictions)\n",
    "\n",
    "        plan_confidence_scores = plan_confidence_scores.detach().cpu().numpy()\n",
    "#         for i in range(predictions.shape[0]):\n",
    "#             plan_confidence_scores[i] = _softmax_normalize(plan_confidence_scores[i])\n",
    "#         print(\"plan_confidence_scores: \", plan_confidence_scores)\n",
    "\n",
    "        pred_request_confidence_scores = pred_request_confidence_scores.detach().cpu().numpy()\n",
    "#         print(\"pred_request_confidence_scores: \", pred_request_confidence_scores)\n",
    "\n",
    "        if sdc_loss is not None:\n",
    "            ground_truth = batch['ground_truth_trajectory'].detach().cpu().numpy()\n",
    "            sdc_loss.cache_batch_losses(\n",
    "                predictions_list=predictions,\n",
    "                ground_truth_batch=ground_truth,\n",
    "                plan_confidence_scores_list=plan_confidence_scores,\n",
    "                pred_request_confidence_scores=pred_request_confidence_scores)\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                'predictions_list': predictions[i],\n",
    "                'plan_confidence_scores_list': plan_confidence_scores[i],\n",
    "                # Negate, as we need to provide an uncertainty measure\n",
    "                # for the submission pb, not a confidence score.\n",
    "                'pred_request_uncertainty_measure':\n",
    "                    -(pred_request_confidence_scores[i])\n",
    "            } for i in range(predictions.shape[0])]\n",
    "\n",
    "# Initialize and load ensemble of k models from checkpoints\n",
    "# On first run, will fail and create a directory where checkpoints\n",
    "# should be placed.\n",
    "model = Model(c=c)\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd9d6a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataloaders with kwargs {'batch_size': 512, 'num_workers': 4, 'prefetch_factor': 2, 'pin_memory': True}.\n"
     ]
    }
   ],
   "source": [
    "# Init dataloader\n",
    "dataloader_kwargs = {\n",
    "    'batch_size': c.exp_batch_size,\n",
    "    'num_workers': c.data_num_workers,\n",
    "    'prefetch_factor': c.data_prefetch_factor,\n",
    "    'pin_memory': True\n",
    "}\n",
    "\n",
    "print(f'Building dataloaders with kwargs {dataloader_kwargs}.')\n",
    "evaluation_dataloader = torch.utils.data.DataLoader(evaluation_dataset, **dataloader_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54a748",
   "metadata": {},
   "source": [
    "### Produce a Submission Protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "814e1943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c468bad945b4f6d946e8009573849e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = Submission()\n",
    "\n",
    "batch_cast = partial(\n",
    "    batch_transform, device=c.exp_device, downsample_hw=None,\n",
    "    data_use_prerendered=True)\n",
    "\n",
    "for batch_id, batch in enumerate(tqdm.tqdm(evaluation_dataloader)):\n",
    "    batch = batch_cast(batch)\n",
    "    batch_output = model.predict(batch, None)\n",
    "\n",
    "    for i, data_item_output in enumerate(batch_output):\n",
    "        proto = object_prediction_from_model_output(\n",
    "            track_id=batch['track_id'][i],\n",
    "            scene_id=batch['scene_id'][i],\n",
    "            model_output=data_item_output,\n",
    "            is_ood=False)  # Set fake value as we do not know is_ood for evaluation data.\n",
    "\n",
    "        submission.predictions.append(proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92f3d02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512652"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's write out a submission protobuf (as one should submit for the competition).\n",
    "save_submission_proto('eval_moscow_and_ood_submission.pb', submission=submission)\n",
    "# Can check that things were written correctly as follows:\n",
    "new_sub = load_submission_proto('eval_moscow_and_ood_submission.pb')\n",
    "len(new_sub.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6aee30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's write out a submission protobuf (as one should submit for the competition).\n",
    "save_submission_proto(submission_dir \\\n",
    "                      + '/'+ model.full_model_name + '_submission.pb', submission=submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82b0b60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512652"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can check that things were written correctly as follows:\n",
    "new_sub = load_submission_proto(submission_dir +\\\n",
    "                                  '/'+ model.full_model_name + '_submission.pb')\n",
    "len(new_sub.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fcc326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
