{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a26484ea-0532-494f-8ed3-a0dd9541c6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.37.0)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.7.4)\n",
      "Using cached transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.37.0\n",
      "    Uninstalling transformers-4.37.0:\n",
      "      Successfully uninstalled transformers-4.37.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "trl 0.13.0 requires accelerate>=0.34.0, but you have accelerate 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.21.0 transformers-4.48.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2277a00e-c1aa-4949-a1c9-abe39f2b11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping qwen as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping qwen2 as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y qwen qwen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89a034d8-ec7c-407d-a618-807e3802b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Hugging Face API 토큰을 입력합니다.\n",
    "api_token = \"put your token\"\n",
    "login(api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea5d06c5-daf2-4917-b4a1-d1fd21a1aa17",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'qwen2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:461\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    459\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 461\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py:998\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;129m@replace_list_option_in_docstrings\u001b[39m()\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    956\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    Instantiate one of the configuration classes of the library from a pretrained model configuration.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m    The configuration class to instantiate is selected based on the `model_type` property of the config object that\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;124;03m    is loaded, or when it's missing, by falling back to using pattern matching on `pretrained_model_name_or_path`:\u001b[39;00m\n\u001b[1;32m    961\u001b[0m \n\u001b[1;32m    962\u001b[0m \u001b[38;5;124;03m    List options\u001b[39;00m\n\u001b[1;32m    963\u001b[0m \n\u001b[1;32m    964\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;124;03m        pretrained_model_name_or_path (`str` or `os.PathLike`):\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;124;03m            Can be either:\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \n\u001b[1;32m    968\u001b[0m \u001b[38;5;124;03m                - A string, the *model id* of a pretrained model configuration hosted inside a model repo on\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;124;03m                  huggingface.co.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;124;03m                - A path to a *directory* containing a configuration file saved using the\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m                  [`~PretrainedConfig.save_pretrained`] method, or the [`~PreTrainedModel.save_pretrained`] method,\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;124;03m                  e.g., `./my_model_directory/`.\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;03m                - A path or url to a saved configuration JSON *file*, e.g.,\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;03m                  `./my_model_directory/configuration.json`.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;124;03m        cache_dir (`str` or `os.PathLike`, *optional*):\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;124;03m            Path to a directory in which a downloaded pretrained model configuration should be cached if the\u001b[39;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;124;03m            standard cache should not be used.\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;124;03m        force_download (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;124;03m            Whether or not to force the (re-)download the model weights and configuration files and override the\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;124;03m            cached versions if they exist.\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;124;03m        resume_download:\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03m            Deprecated and ignored. All downloads are now resumed by default when possible.\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;124;03m            Will be removed in v5 of Transformers.\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;124;03m        proxies (`Dict[str, str]`, *optional*):\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;124;03m            A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128',\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;124;03m            'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;124;03m        revision (`str`, *optional*, defaults to `\"main\"`):\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;124;03m            The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;124;03m            git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m            identifier allowed by git.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m        return_unused_kwargs (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;124;03m            If `False`, then this function returns just the final configuration object.\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \n\u001b[1;32m    994\u001b[0m \u001b[38;5;124;03m            If `True`, then this functions returns a `Tuple(config, unused_kwargs)` where *unused_kwargs* is a\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03m            dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;124;03m            part of `kwargs` which has not been used to update `config` and is otherwise ignored.\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m        trust_remote_code (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;124;03m            Whether or not to allow for custom models defined on the Hub in their own modeling files. This option\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;124;03m            should only be set to `True` for repositories you trust and in which you have read the code, as it will\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;124;03m            execute code present on the Hub on your local machine.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;124;03m        kwargs(additional keyword arguments, *optional*):\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;124;03m            The values in kwargs of any keys which are configuration attributes will be used to override the loaded\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;124;03m            values. Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;124;03m            by the `return_unused_kwargs` keyword parameter.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m \n\u001b[1;32m   1006\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \n\u001b[1;32m   1008\u001b[0m \u001b[38;5;124;03m    ```python\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;124;03m    >>> from transformers import AutoConfig\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m    >>> # Download configuration from huggingface.co and cache.\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03m    >>> config = AutoConfig.from_pretrained(\"google-bert/bert-base-uncased\")\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \n\u001b[1;32m   1014\u001b[0m \u001b[38;5;124;03m    >>> # Download configuration from huggingface.co (user-uploaded) and cache.\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;124;03m    >>> config = AutoConfig.from_pretrained(\"dbmdz/bert-base-german-cased\")\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m    >>> # If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m    >>> config = AutoConfig.from_pretrained(\"./test/bert_saved_model/\")\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \n\u001b[1;32m   1020\u001b[0m \u001b[38;5;124;03m    >>> # Load a specific configuration file.\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;124;03m    >>> config = AutoConfig.from_pretrained(\"./test/bert_saved_model/my_configuration.json\")\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03m    >>> # Change some config attributes when loading a pretrained config.\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;124;03m    >>> config = AutoConfig.from_pretrained(\"google-bert/bert-base-uncased\", output_attentions=True, foo=False)\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;03m    >>> config.output_attentions\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m    >>> config, unused_kwargs = AutoConfig.from_pretrained(\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m    ...     \"google-bert/bert-base-uncased\", output_attentions=True, foo=False, return_unused_kwargs=True\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;03m    ... )\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;124;03m    >>> config.output_attentions\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m    >>> unused_kwargs\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    {'foo': False}\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     use_auth_token \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_auth_token\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_auth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py:710\u001b[0m, in \u001b[0;36m_LazyConfigMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_content[key]\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping:\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    711\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping[key]\n\u001b[1;32m    712\u001b[0m module_name \u001b[38;5;241m=\u001b[39m model_type_to_module_name(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'qwen2'"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", trust_remote_code=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ed64c71-d22d-4a05-b5b4-b911b6d110f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.48.2\n",
      "Uninstalling transformers-4.48.2:\n",
      "  Successfully uninstalled transformers-4.48.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a23e7ae-c85e-40ca-9206-692e1958fe5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-aj265ib0\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-aj265ib0\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 62db3e6ed67a74cc1ed1436acd9973915c0a4475\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.49.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.49.0.dev0) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.49.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.49.0.dev0) (2024.7.4)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.49.0.dev0-py3-none-any.whl size=10627237 sha256=6d43344d0228646154a3446e15683566a3843171360bfc07e7df57ecb9f399f7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-y1z6g5fj/wheels/32/4b/78/f195c684dd3a9ed21f3b39fe8f85b48df7918581b6437be143\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "trl 0.13.0 requires accelerate>=0.34.0, but you have accelerate 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed transformers-4.49.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ee9b8f8-9639-4ddf-97e3-04df3715cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지원되는 모델 목록: ['albert', 'align', 'altclip', 'audio-spectrogram-transformer', 'autoformer', 'bark', 'bart', 'beit', 'bert', 'bert-generation', 'big_bird', 'bigbird_pegasus', 'biogpt', 'bit', 'blenderbot', 'blenderbot-small', 'blip', 'blip-2', 'bloom', 'bridgetower', 'camembert', 'canine', 'chinese_clip', 'clap', 'clip', 'clipseg', 'codegen', 'conditional_detr', 'convbert', 'convnext', 'convnextv2', 'cpmant', 'ctrl', 'cvt', 'data2vec-audio', 'data2vec-text', 'data2vec-vision', 'deberta', 'deberta-v2', 'decision_transformer', 'deformable_detr', 'deit', 'deta', 'detr', 'dinat', 'distilbert', 'donut-swin', 'dpr', 'dpt', 'efficientformer', 'efficientnet', 'electra', 'encodec', 'encoder-decoder', 'ernie', 'ernie_m', 'esm', 'falcon', 'flaubert', 'flava', 'fnet', 'focalnet', 'fsmt', 'funnel', 'git', 'glpn', 'gpt-sw3', 'gpt2', 'gpt_bigcode', 'gpt_neo', 'gpt_neox', 'gpt_neox_japanese', 'gptj', 'gptsan-japanese', 'graphormer', 'groupvit', 'hubert', 'ibert', 'imagegpt', 'informer', 'instructblip', 'jukebox', 'layoutlm', 'layoutlmv2', 'layoutlmv3', 'led', 'levit', 'lilt', 'llama', 'longformer', 'longt5', 'luke', 'lxmert', 'm2m_100', 'marian', 'markuplm', 'mask2former', 'maskformer', 'maskformer-swin', 'mbart', 'mctct', 'mega', 'megatron-bert', 'mgp-str', 'mobilebert', 'mobilenet_v1', 'mobilenet_v2', 'mobilevit', 'mobilevitv2', 'mpnet', 'mra', 'mt5', 'musicgen', 'mvp', 'nat', 'nezha', 'nllb-moe', 'nystromformer', 'oneformer', 'open-llama', 'openai-gpt', 'opt', 'owlvit', 'pegasus', 'pegasus_x', 'perceiver', 'pix2struct', 'plbart', 'poolformer', 'prophetnet', 'qdqbert', 'rag', 'realm', 'reformer', 'regnet', 'rembert', 'resnet', 'retribert', 'roberta', 'roberta-prelayernorm', 'roc_bert', 'roformer', 'rwkv', 'sam', 'segformer', 'sew', 'sew-d', 'speech-encoder-decoder', 'speech_to_text', 'speech_to_text_2', 'speecht5', 'splinter', 'squeezebert', 'swiftformer', 'swin', 'swin2sr', 'swinv2', 'switch_transformers', 't5', 'table-transformer', 'tapas', 'time_series_transformer', 'timesformer', 'timm_backbone', 'trajectory_transformer', 'transfo-xl', 'trocr', 'tvlt', 'umt5', 'unispeech', 'unispeech-sat', 'upernet', 'van', 'videomae', 'vilt', 'vision-encoder-decoder', 'vision-text-dual-encoder', 'visual_bert', 'vit', 'vit_hybrid', 'vit_mae', 'vit_msn', 'vivit', 'wav2vec2', 'wav2vec2-conformer', 'wavlm', 'whisper', 'xclip', 'xglm', 'xlm', 'xlm-prophetnet', 'xlm-roberta', 'xlm-roberta-xl', 'xlnet', 'xmod', 'yolos', 'yoso']\n"
     ]
    }
   ],
   "source": [
    "from transformers import CONFIG_MAPPING\n",
    "\n",
    "print(\"지원되는 모델 목록:\", CONFIG_MAPPING.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dd9827a-3f73-4e5b-b609-18f923e5a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: vllm\n",
      "Version: 0.7.1\n",
      "Summary: A high-throughput and memory-efficient inference and serving engine for LLMs\n",
      "Home-page: https://github.com/vllm-project/vllm\n",
      "Author: vLLM Team\n",
      "Author-email: \n",
      "License: Apache 2.0\n",
      "Location: /usr/local/lib/python3.11/dist-packages\n",
      "Requires: aiohttp, blake3, cloudpickle, compressed-tensors, depyf, einops, fastapi, filelock, gguf, importlib_metadata, lark, lm-format-enforcer, mistral_common, msgspec, numpy, nvidia-ml-py, openai, outlines, partial-json-parser, pillow, prometheus-fastapi-instrumentator, prometheus_client, protobuf, psutil, py-cpuinfo, pydantic, pyyaml, pyzmq, ray, requests, sentencepiece, tiktoken, tokenizers, torch, torchaudio, torchvision, tqdm, transformers, typing_extensions, uvicorn, xformers, xgrammar\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show vllm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a95616-8836-483e-b7c0-10ec8d1187e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
